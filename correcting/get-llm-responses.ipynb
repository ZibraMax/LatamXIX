{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Get the LLM for the correction request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first look at the texts to be corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La publicacion del Oso se harà dos veces cada se mana, y constará de un pliego en cuarto ; ofreciendo à mas sus redactores, dar los gravados oportunos, siempre que loexija el asuntode que trate. Redactado por un Num. 8. TEMA del Periodico. POLITICA MILITAR. OCTAVA SESION. Abierta la sesion á las dore y un minuto de la noche , 25 de Febrero de 1845 , con asistencia de todos los Señores Representantes, se leyó y aprobó la acta de la Asamblea anterior , ménos en lo tocante à la torre del Convento de Santo Domingo, punto que quedó para ventilarse en mejor ocasion. En seguida se dió cuenta de una nota del Ejecutivo , referente à que urjía la necesidad de organizar un Ejército ; pues decia el Excmo. Decano: - \"Un poder sin bayonetas vale tanto como un cero puesto á la izquierda.\"\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../data/cleaned-latam-xix.parquet\")\n",
    "\n",
    "'''La publicacion del Oso se harà dos veces cada se mana, y constará de un pliego en cuarto ; \n",
    "ofreciendo à mas sus redactores, dar los gravados oportunos, siempre que loexija el asuntode \n",
    "que trate. Redactado por un Num. 8. TEMA del Periodico. POLITICA MILITAR. OCTAVA SESION. \n",
    "Abierta la sesion á las dore y un minuto de la noche , 25 de Febrero de 1845 , con asistencia \n",
    "de todos los Señores Representantes, se leyó y aprobó la acta de la Asamblea anterior , \n",
    "ménos en lo tocante à la torre del Convento de Santo Domingo, punto que quedó para ventilarse \n",
    "en mejor ocasion. En seguida se dió cuenta de una nota del Ejecutivo , referente à que urjía \n",
    "la necesidad de organizar un Ejército ; pues decia el Excmo. Decano: - \"Un poder sin bayonetas \n",
    "vale tanto como un cero puesto á la izquierda.\"'''\n",
    "print(df.loc[0, \"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the LLM API Client and request parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the LLM is GPT in it's **GPT 3.5 Turbo** version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('./gpt35.env')\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_ENDPOINT\")\n",
    "engine=os.getenv(\"OPENAI_IMPLEMENTATION\")\n",
    "model=os.getenv(\"MODEL_NAME\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(prompt, max_tokens=500, temperature=0):\n",
    "    \"\"\"Request a completion from the OpenAI API.\n",
    "    :param prompt: The prompt to send to the API\n",
    "    :param max_tokens: The maximum number of tokens in the output\n",
    "    :param temperature: The degree of randomness in the output\n",
    "    :return response: The response from the API\n",
    "    :return usage: The count of token usage from the API { \"input\", \"output\" }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            api_key=api_key,\n",
    "            api_base=api_base,\n",
    "            engine=engine,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        finish_reason = response[\"choices\"][0][\"finish_reason\"]\n",
    "        rsp = \"\" if finish_reason == \"content_filter\" else response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return rsp, { \"input\": response[\"usage\"][\"prompt_tokens\"], \"output\": response[\"usage\"][\"completion_tokens\"] }, finish_reason\n",
    "    except Exception as e:\n",
    "        response = \"\"\n",
    "        usage = {\"input\": 0, \"output\": 0}\n",
    "        if f\"{e}\".startswith(\"The response was filtered due to the prompt triggering Azure OpenAI's content management policy\"):\n",
    "            finish_reason = \"content_filter\"\n",
    "        else:\n",
    "            if \"Max retries exceeded with url\" in f\"{e}\":\n",
    "                time.sleep(60)\n",
    "                return request(prompt, max_tokens, temperature) # retry after 60 seconds\n",
    "            finish_reason = f\"ERROR [{type(e).__name__}]: {e}\"\n",
    "        return response, usage, finish_reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the prompt to send with the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_start = 'Dado el texto entre ```, retorna únicamente el texto corrigiendo los errores ortográficos sin cambiar la gramática:\\n```\\n'\n",
    "# text\n",
    "prompt_end = '\\n```'\n",
    "gen_prompt = lambda text: f\"{prompt_start}{text}{prompt_end}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recover the information from the last execution and avoid the lost of data if an error occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSES_FILE = \"./responsesLatam.json\"\n",
    "\n",
    "r = {\"data\":[], \"checkpoint\": 0, \"input_tokens\": 0, \"output_tokens\": 0}\n",
    "if os.path.exists(RESPONSES_FILE):\n",
    "    with open(RESPONSES_FILE, \"r\") as f:\n",
    "        r = json.load(f)\n",
    "else:\n",
    "    with open(RESPONSES_FILE, \"w\") as f:\n",
    "        f.write(json.dumps(r, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10176/10176 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "assert r['checkpoint'] == len(r['data']), \"Checkpoint does not match with corrected texts\"\n",
    "print(f\"Done {r['checkpoint']}/{len(df)} ({100*r['checkpoint']/len(df):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Send the requests to the API and store them periodically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in df.loc[r['checkpoint']:, \"text\"]:\n",
    "    prompt = gen_prompt(text)\n",
    "    print(f\"------------------------------- {r['checkpoint']} -----------------------------------\")\n",
    "    print(prompt)\n",
    "    response, usage, finish_reason = request(prompt)\n",
    "    print(response)\n",
    "    r[\"input_tokens\"] += usage[\"input\"]\n",
    "    r[\"output_tokens\"] += usage[\"output\"]\n",
    "\n",
    "    r[\"data\"].append({\n",
    "        \"text\": text,\n",
    "        \"resp\": response,\n",
    "        \"finish_reason\": finish_reason\n",
    "    })\n",
    "\n",
    "    r[\"checkpoint\"] += 1\n",
    "\n",
    "    if r['checkpoint'] % 10 == 0:\n",
    "        with open(RESPONSES_FILE, \"w\") as f:\n",
    "            f.write(json.dumps(r, indent=4))\n",
    "        print(f\"SAVED ({r['checkpoint']})\")\n",
    "\n",
    "with open(RESPONSES_FILE, \"w\") as f:\n",
    "    f.write(json.dumps(r, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be empty responses due to errors when sending the request. Some of them are due to connection issues, and others due to the OpenAI's content management policy. In this case, the request, can be run manually when there are only a few cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The following requests must be repeated manually (due to OpenAI's content filter or an error):\\n\")\n",
    "for i,e in enumerate(r[\"data\"]):\n",
    "    if e[\"finish_reason\"] == \"content_filter\" or e[\"finish_reason\"].startswith(\"ERROR\"):\n",
    "        print(f\"------------------------------- {i} -----------------------------------\")\n",
    "        print(gen_prompt(e['text']))\n",
    "\n",
    "# put the responses in the dictionary and run the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "manually_req_responses = {\n",
    "    269: '''175 para llamar la atención del Sr. Intendente de Policía sobre esa cruel y mal entendida economía que adoptan siempre los rejoneadores. Estos, en vez de entrar a la plaza en caballos que por su brío y buena rienda puedan librarse y salvar a sus jinetes de una muerte casi cierta, se presentan en caballos que más parecen perros galgos que caballos. Los entregan a las astas del toro a propósito y después de mil y mil fatigas, presentan al público un espectáculo no solo asqueroso, sino hasta bárbaro y cruel. ¡Cuántas veces no hemos visto esas pobres bestias, con los intestinos fuera, correteando y regando bajo las piernas de un bravo toro, con su sangre toda la plaza! La Intendencia debe ser muy severa a este respecto, y negar el premio que tan cruel y ferozmente exigen estos bárbaros. ¿Qué les importa, en efecto, sacrificar un caballo cuando lo tienen pagado a costa de la vida del mismo animal? ¿Qué mérito puede presentar esta clase de espectáculos cuando en ellos ya no hace alarde el lidiador de la destreza que debe? Esperamos pues que el Sr. Intendente corrija tan feroz abuso y si es posible, castigue al que no cumpla con el primero de los deberes, la humanidad. AVISOS Suplicamos a nuestros lectores disimulen, que no haya salido este número con la exactitud que los demás, pues tres oficiales de los que trabajaban en nuestro periódico se han despedido sin darnos el tiempo necesario para reemplazarlos. Los versos que insertamos a continuación los reimprimimos hoy, a petición de diez y siete de nuestros SS. escritores.''',\n",
    "}\n",
    "\n",
    "for i,e in enumerate(r[\"data\"]):\n",
    "    if e[\"finish_reason\"] == \"content_filter\" or e[\"finish_reason\"].startswith(\"ERROR\"):\n",
    "        print(f\"------------------------------- {i} -----------------------------------\")\n",
    "        print(r[\"data\"][i]['text'])\n",
    "        if i in manually_req_responses:\n",
    "            r[\"data\"][i][\"resp\"] = manually_req_responses[i]\n",
    "            r[\"data\"][i][\"finish_reason\"] = \"stop\"\n",
    "            print(r[\"data\"][i][\"resp\"])\n",
    "            print(f\"Index {i} OK\")\n",
    "        else:\n",
    "            print(f\"Index {i} NOT FOUND\")\n",
    "\n",
    "with open(RESPONSES_FILE, \"w\") as f:\n",
    "    f.write(json.dumps(r, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
